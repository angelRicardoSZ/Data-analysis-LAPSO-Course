guides(colour = guide_legend(title = "Fourier Transform pairs")) +
scale_color_discrete(breaks =a)
tslm_ft_gasolina_hasta_2004.name <- paste(
"tslm_ft", 1, "_gasoline_until_2004",
sep = ""
)
for (j in a){
tslm_ft_gasolina_hasta_2004.name <- paste(
"tslm_ft", as.character(i), "_gasoline_until_2004",
sep = ""
)
writeLines(
paste(
"\n", tslm_ft_gasolina_hasta_2004.name, "\n"
)
)
print(CV(get(tslm_ft_gasolina_hasta_2004.name)))
}
for (j in a){
tslm_ft_gasolina_hasta_2004.name <- paste(
"tslm_ft", as.character(j), "_gasoline_until_2004",
sep = ""
)
writeLines(
paste(
"\n", tslm_ft_gasolina_hasta_2004.name, "\n"
)
)
print(CV(get(tslm_ft_gasolina_hasta_2004.name)))
}
for (j in a){
tslm_ft_gasolina_hasta_2004.name <- paste(
"tslm_ft", as.character(j), "_gasolina_hasta_2004",
sep = ""
)
writeLines(
paste(
"\n", tslm_ft_gasolina_hasta_2004.name, "\n"
)
)
print(CV(get(tslm_ft_gasolina_hasta_2004.name)))
}
for (j in a){
tslm_ft_gasolina_hasta_2004.name <- paste(
"tslm_ft", as.character(j), "_gasolina_hasta_2004",
sep = ""
)
writeLines(
paste(
tslm_ft_gasolina_hasta_2004.name, "\n"
)
)
print(CV(get(tslm_ft_gasolina_hasta_2004.name)))
}
min_AICc <- Inf
min_AICc
min_AICc <- Inf
min_K_by_AICc <- 0
min_CV <- Inf
min_K_by_CV <- 0
AICc_K <- 0
CV_K <- 0
for(num in 1:26){
AICc_K <- CV(
tslm(
gasoline_until_2004 ~ trend + fourier(gasoline_until_2004, K = num)
)
)[["AICc"]]
print(AICc_K)
CV_K <- CV(
tslm(
gasoline_until_2004 ~ trend + fourier(gasoline_until_2004, K = num)
)
)[["CV"]]
print(CV_K)
# If the minimum AICc and CV values are found, the loop don't need to run anymore. Therefore print the result number of pairs and break the loop.
# If num = 1, don't run below codes and move to num = 2. With just the result of num = 1, I cannot know whether the AICc and CV values are minimum.
if(num != 1){
if(AICc_K >= min_AICc & CV_K >= min_CV){
writeLines(
paste("The number of Fourier Transform pairs to minimize AICc",
"\n",
as.character(min_K_by_AICc)
)
)
writeLines(
paste("The number of Fourier Transform pairs to minimize CV",
"\n",
as.character(min_K_by_CV)
)
)
break
}
}
# find the minimum AICc and CV and the number of pairs at the state.
if(AICc_K < min_AICc){
min_AICc <- AICc_K
min_K_by_AICc <- num
}
if(CV_K < min_CV){
min_CV <- CV_K
min_K_by_CV <- num
}
}
for(num in 1:26){
AICc_K <- CV(
tslm(
gasolina_hasta_2004 ~ trend + fourier(gasolina_hasta_2004, K = num)
)
)[["AICc"]]
print(AICc_K)
CV_K <- CV(
tslm(
gasolina_hasta_2004 ~ trend + fourier(gasolina_hasta_2004, K = num)
)
)[["CV"]]
print(CV_K)
# If the minimum AICc and CV values are found, the loop don't need to run anymore. Therefore print the result number of pairs and break the loop.
# If num = 1, don't run below codes and move to num = 2. With just the result of num = 1, I cannot know whether the AICc and CV values are minimum.
if(num != 1){
if(AICc_K >= min_AICc & CV_K >= min_CV){
writeLines(
paste("The number of Fourier Transform pairs to minimize AICc",
"\n",
as.character(min_K_by_AICc)
)
)
writeLines(
paste("The number of Fourier Transform pairs to minimize CV",
"\n",
as.character(min_K_by_CV)
)
)
break
}
}
# find the minimum AICc and CV and the number of pairs at the state.
if(AICc_K < min_AICc){
min_AICc <- AICc_K
min_K_by_AICc <- num
}
if(CV_K < min_CV){
min_CV <- CV_K
min_K_by_CV <- num
}
}
tslm_ft7_gasolina_hasta_2004 <- tslm(
gasolina_hasta_2004 ~ trend + fourier(
gasolina_hasta_2004,
K = 7
)
)
checkresiduals(tslm_ft7_gasolina_hasta_2004)
fc_gasoline_2005 <- forecast(
tslm_ft7_gasolina_hasta_2004,
newdata=data.frame(fourier(
gasoline_until_2004, K = 7, h = 52)
)
)
fc_gasoline_2005 <- forecast(
tslm_ft7_gasolina_hasta_2004,
newdata=data.frame(fourier(
gasolina_hasta_2004, K = 7, h = 52)
)
)
autoplot(fc_gasoline_2005) +
autolayer(window(
gasoline,
start = 2004,
end = 2006
)
) +
scale_x_continuous(limits = c(2004, 2006))
library(forecast)
library(fpp2)
library(GGally)
library(ggplot2)
h <- 8
fc_tslm_huron <- forecast(tslm_huron, h=h)
tslm_huron <- tslm(huron ~ trend)
h <- 8
fc_tslm_huron <- forecast(tslm_huron, h=h)
tslm_log_huron <- tslm(huron ~ trend,
lambda = 0)
fc_tslm_log_huron <- forecast(tslm_log_huron, h=h)
t <- time(huron)  #w
t.break <- 1915
t_piece <- ts(pmax(0,t-t.break), start=1875)
tslm_pw_huron <- tslm(huron ~ t + t_piece)
l=length(t)  # 98
t_new <-t[l] + seq(h)  #  the data to forecast
t_piece_new <- t_piece[length(t_piece)]+seq(h)
newdata <- cbind(t=t_new,
t_piece=t_piece_new) %>%
as.data.frame()
fc_tslm_pw_huron <- forecast(
tslm_pw_huron,
newdata = newdata
)
tslm_spline_huron <- splinef(huron, lambda = 0)
fc_tslm_spline_huron <- forecast(
tslm_spline_huron,
newdata = newdata
)
autoplot(huron) +
autolayer(fitted(tslm_huron), series = "Linear") +
autolayer(fitted(tslm_log_huron), series="Logarithm") +
autolayer(fitted(tslm_pw_huron), series = "Piecewise") +
autolayer(fitted(tslm_spline_huron), series = "Cubic Spline") +
autolayer(fc_tslm_pw_huron, series="Piecewise") +
autolayer(fc_tslm_huron$mean, series = "Linear") +
autolayer(fc_tslm_log_huron$mean, series="Logarithm") +
autolayer(fc_tslm_spline_huron$mean, series="Cubic Spline") +
xlab("Year") +  ylab("Water level") +
ggtitle("Lake Huron water level change") +
guides(colour=guide_legend(title=" "))
fitted(tslm_huron)
tslm_huron
fc_tslm_pw_huron
fc_tslm_huron$mean
fc_tslm_huron
autoplot(huron) +
autolayer(fitted(tslm_huron), series = "Linear") +
autolayer(fc_tslm_huron, series = "Linear") +
xlab("Year") +  ylab("Water level") +
ggtitle("Lake Huron water level change",
subtitle = "using Linear Regression model") +
guides(colour=guide_legend(title=" ")) +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
autoplot(huron) +
autolayer(fitted(tslm_pw_huron), series = "Piecewise") +
autolayer(fc_tslm_pw_huron, series="Piecewise") +
xlab("Year") +  ylab("Water level") +
ggtitle("Lake Huron water level change",
subtitle = "using piecewise linear model") +
guides(colour=guide_legend(title=" ")) +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5))
library(forecast)
library(fpp2)
library(GGally)
library(ggplot2)
autoplot(elecsales) + xlab("Year") + ylab("GWh") +
ggtitle("Annual electricity sales: South Australia")
ma(elecsales, 5)
autoplot(elecsales, series="Data") +
autolayer(ma(elecsales,5), series="5-MA") +
xlab("Year") + ylab("GWh") +
ggtitle("Annual electricity sales: South Australia") +
scale_colour_manual(values=c("Data"="grey50","5-MA"="red"),
breaks=c("Data","5-MA"))
autoplot(elecsales, series="Data") +
autolayer(ma(elecsales,5), series="5-MA") +
xlab("Year") + ylab("GWh") +
ggtitle("Annual electricity sales: South Australia") +
scale_colour_manual(values=c("Data"="grey50","5-MA"="blue"),
breaks=c("Data","5-MA"))
beer2 <- window(ausbeer,start=1992)
ma4 <- ma(beer2,order=4,centre = FALSE)
ma2x4 <- ma(beer2, order=4, centre = FALSE)
ma4
ma2x4
ma2x4 <- ma(beer2, order=4, centre = TRUE)
ma2x4
autoplot(elecequip, series="Data") +
autolayer(ma(elecequip, 12), series="12-MA") +
xlab("Year") + ylab("New orders index") +
ggtitle("Electrical equipment manufacturing (Euro area)") +
scale_colour_manual(values=c("Data"="grey","12-MA"="red"),
breaks=c("Data","12-MA"))
elecequip %>% decompose(type="multiplicative") %>%
autoplot() + xlab("Year") +
ggtitle("Classical multiplicative decomposition
of electrical equipment index")
library(seasona
library(seasonal)
library(seasonal)
elecequip %>% seas(x11="") -> fit
fit
autoplot(fit) +
ggtitle("X11 decomposition of electrical equipment index")
trendcycle(fit)
autoplot(elecequip, series="Data") +
autolayer(trendcycle(fit), series="Trend") +
autolayer(seasadj(fit), series="Seasonally Adjusted") +
xlab("Year") + ylab("New orders index") +
ggtitle("Electrical equipment manufacturing (Euro area)") +
scale_colour_manual(values=c("gray","blue","red"),
breaks=c("Data","Seasonally Adjusted","Trend"))
fit %>% seasonal() %>% ggsubseriesplot() + ylab("Seasonal")
library(forecast)
library(fpp2)
library(GGally)
library(ggplot2)
library(seasonal)
elecequip  %>% seas(x11="") -> fit
help("elecequip")
autoplot(fit) +
ggtitle("X11 decomposition of electrical equipement index")
autoplot(elecequip, series = "Data") +
autolayer(trendcycle(fit), series = "Trend" ) +
autolayer(seasadj(fit), series = "Seasonally adjusted") +
xlab("Year") + ylab("New orders index") +
ggtitle("Electrical equipment manufacturing (Euro area)") +
scale_color_manual(values=c("gray", "blue", "red"),
breaks=c("Data", "Seasonally adjusted", "Trend"))
fit %>% seasonal() %>% ggsubseriesplot() + ylab("Seasonal")
elecequip %>% seas() %>%
autoplot() +
ggtitle("SEATS decompition of electrical equipement index")
elecequip %>%
stl(t.window=13, s.window="periodic", robust=TRUE) %>%
autoplot()
fit <- stl(elecequip, t.window = 13, s.window = "periodic", robust = TRUE)
fit %>% seasadj() %>% naive() %>%
autoplot()  + ylab("New orders of index") +
ggtitle("Naive forecasts of seasonally adjusted data")
fit %>% forecast(method="naive") %>%
autoplot() + ylab("New orders index")
fcast <- stlf(elecequip, method='naive')
ICOS
getwd()
setwd("C:\\Users\\wabng\\Documents\\")
getwd()
valor1 <- sqrt((7 + 8) ^ 3 )
valor1
manzanas <- 8
naranjas <- 3
frutas <- manzanas + naranjas
frutas
promedio<-mean(c(manzanas, naranjas))  # Convierte a vector y luego toma
promedio
class(manzanas)
class(FALSE)
manzanas > naranjas
manzanas < naranjas
var1 <- c(1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5)
var1
var1 + var1
1:12
1:10 + 1:5 # Entender c'omo recicla vectores
matrix()
matrix(data = 1:9, nrow = 3, ncol = 3, byrow = TRUE)
matrix(data = 1:9, nrow = 3, ncol = 3, byrow = F)
data()
data("Orange")
View(Orange)
df<-data.frame(var1,word=7:15,anio=rep(1,9))
View(df)
str(df)  # nos da la estructura del df
list_a<-list(vector=var1, data=df, vector2=1:7)
list_a
list_a$data$word  # acceder al df  y luego a una columna
str(list_a)
install.packages("tidyr")
?lm
args(lm)
TRUE == FALSE
-6*14 != 17-101
"Abril" > "Mayo"
setwd("C:/Users/wabng/Documents/Data science/Curso LAPSO/Week 10")
rm(list=ls())
setwd("~/Data science/Curso LAPSO/Week 10")
library(ggplot2)
options(repr.plot.width = 9, repr.plot.height=5 )
data("economics")
data("economics")
recess <- data.frame(inicio=as.Date(c("1969-12-01","1973-11-01","1980-01-01",
"1981-07-01","1990-07-01","2001-03-01")),
fin=as.Date(c("1970-11-01","1975-03-01","1980-07-01",
"1982-11-01","1991-03-01","2001-11-01")))
ggplot(economics, aes(x = date, y = unemploy/pop)) +
geom_rect(data = recess,
aes(xmin = inicio, xmax = fin, ymin = -Inf, ymax = +Inf),
inherit.aes = FALSE, fill = "blue", alpha = 0.2) +
geom_line()
ggplot(economics, aes(x = date, y = unemploy/pop)) +
geom_rect(data = recess,
aes(xmin = inicio, xmax = fin, ymin = 0.02, ymax = 0.05),
inherit.aes = FALSE, fill = "blue", alpha = 0.2) +
geom_line()
rm(list=ls())
base <- read.csv("EconomistData.csv")
head(base)
pc1 <- ggplot(base, aes(x=CPI, y=HDI, color=REGION ))
pc1 + geom_point()
pc1 <- ggplot(base, aes(x=CPI, y=HDI, color=Region ))
pc1 + geom_point()
pc2 <- ggplot(base, aes(x=CPI, y=HDI, color=Region )) + stat_smooth()
pc2 + geom_point()
pc2 + geom_point(SE =F)
pc2 <- ggplot(base, aes(x=CPI, y=HDI, color=Region )) + stat_smooth(se =F,color="red")
pc2 + geom_point()
pc3 <- pc2 + geom_point(shape=1, size=2.5, stroke=1.25)
pc3
etiquetas <- c("Russia", "Venezuela", "Iraq", "Myanmar", "Sudan",
"Afghanistan", "Congo", "Greece", "Argentina", "Brazil",
"India", "Italy", "China", "South Africa", "Spane",
"Botswana", "Cape Verde", "Bhutan", "Rwanda", "France",
"United States", "Germany", "Britain", "Barbados", "Norway", "Japan",
"New Zealand", "Singapore")
etiquetas
install.packages("ggrepel")
library(ggrepel)
head(base)
filter(dat, Country %in% etiquetas)
filter(base, Country %in% etiquetas)
dpylr::filter(base, Country %in% etiquetas)
library(dpylr)
library(dplyr)
dplyr::filter(base, Country %in% etiquetas)
basefiltrada <-dplyr::filter(base, Country %in% etiquetas)
head(basefiltrada)
pc4 <- pc3 +
geom_text_repel(aes(label=Country),
color="gray20",
data = basefiltrada,
force = 10)
pc4
pc5 <- pc4 +
scale_x_continuous(name = "Índice de Percepción de la Corrupción, 2011 (10=menos corrupto)",
limits = c(.9, 10.5),
breaks = 1:10) +
scale_y_continuous(name = "Índice de Desarrollo Humano, 2011 (1=Mejor)",
limits = c(0.2, 1.0),
breaks = seq(0.2, 1.0, by = 0.1)) +
scale_color_manual(name = "",
values = c("#24576D",
"#099DD7",
"#28AADC",
"#248E84",
"#F2583F",
"#96503F")) +
theme_minimal()+
ggtitle("Corrupción y desarrollo humano")
pc5
install.packages("rvest", dependencies = TRUE)
setwd("C:/Users/wabng/Documents/Data science/Curso LAPSO/Week 11")
setwd("~/Data science/Curso LAPSO/Week 11")
library(rvest)
html <- read_html("https://admissions.calpoly.edu/prospective/profile.html")
prim.t <- html %>%  html_nodes("table") %>% .[[2]]
prim.t %>% html_table()
titulos <- read_html(URL) %>%
html_nodes("h2.a-size-base.s-inline.s-access-title.a-text-normal") %>%
html_text()
precios <- read_html(URL) %>%
html_nodes("span.a-size-base.a-color-price.s-price.a-text-bold") %>% html_text()
df <- data.frame(titulos, precios)
URL <- "https://www.amazon.com.mx/b/ref=s9_acss_bw_cg_CS_2b1_w?ie=UTF8&node=9784573011&pf_rd_m=A3TO6F13CSVUA4&pf_rd_s=merchandised-search-5&pf_rd_r=9XA9HKGT4TAED22RZW6A&pf_rd_t=101&pf_rd_p=c880d6e9-69fc-4402-acc0-2e3d6a3e84d5&pf_rd_i=9784530011"
titulos <- read_html(URL) %>%
html_nodes("h2.a-size-base.s-inline.s-access-title.a-text-normal") %>%
html_text()
precios <- read_html(URL) %>%
html_nodes("span.a-size-base.a-color-price.s-price.a-text-bold") %>% html_text()
df <- data.frame(titulos, precios)
rm(list=ls())
URL <- "https://www.amazon.com.mx/b/ref=s9_acss_bw_cg_CS_2b1_w?ie=UTF8&node=9784573011&pf_rd_m=A3TO6F13CSVUA4&pf_rd_s=merchandised-search-5&pf_rd_r=9XA9HKGT4TAED22RZW6A&pf_rd_t=101&pf_rd_p=c880d6e9-69fc-4402-acc0-2e3d6a3e84d5&pf_rd_i=9784530011"
titulos <- read_html(URL) %>%
html_nodes("h2.a-size-base.s-inline.s-access-title.a-text-normal") %>%
html_text()
precios <- read_html(URL) %>%
html_nodes("span.a-size-base.a-color-price.s-price.a-text-bold") %>% html_text()
df <- data.frame(titulos, precios)
df <- data.frame(titulos)
df
df2 <- data.frame(precios)
head(df2)
library(dplyr)
URLs <- "https://deportes.mercadolibre.com.mx/bicicletas-ciclismo/bicicletas/_Desde_"
for (i in c(1,51)) {
titulos <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.main-title") %>%
html_text()
precios <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.price__fraction") %>% html_text()
df <- bind_rows(df, data.frame(titulos, precios))
print(paste("Termina elemento ", i, sep=""))
}
View(df)
rm(list=ls())
URLs <- "https://deportes.mercadolibre.com.mx/bicicletas-ciclismo/bicicletas/_Desde_"
for (i in c(1,51)) {
titulos <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.main-title") %>%
html_text()
precios <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.price__fraction") %>% html_text()
df <- bind_rows(df, data.frame(titulos, precios))
print(paste("Termina elemento ", i, sep=""))
}
rm(list=ls())
for (i in c(1,51)) {
titulos <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.main-title") %>%
html_text()
precios <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.price__fraction") %>% html_text()
df <- bind_rows(df, data.frame(titulos, precios))
print(paste("Termina elemento ", i, sep=""))
}
URLs <- "https://deportes.mercadolibre.com.mx/bicicletas-ciclismo/bicicletas/_Desde_"
for (i in c(1,51)) {
titulos <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.main-title") %>%
html_text()
precios <- read_html(paste(URLs, i, sep="")) %>%
html_nodes("span.price__fraction") %>% html_text()
df <- bind_rows(df, data.frame(titulos, precios))
print(paste("Termina elemento ", i, sep=""))
}
